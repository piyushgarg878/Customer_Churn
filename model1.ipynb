{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f16579-723a-4ac4-9769-f4abcd4601cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d1b57-1f8f-4538-bea4-674868b7aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('Dataset.xlsx',sheet_name='E Comm')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47af6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85cf7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84848ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].dtypes == 'object':\n",
    "        print(i)\n",
    "        print()\n",
    "        print('the values are:') \n",
    "        print(df[i].value_counts())\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CustomerID'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].isnull().sum() > 0:\n",
    "        print(i)\n",
    "        print('the total null values are:', df[i].isnull().sum())\n",
    "        print('the datatype is', df[i].dtypes)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'] = df['Churn'].astype('object')\n",
    "df['CityTier'] = df['CityTier'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fe0990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].isnull().sum() > 0:\n",
    "        df[i]=df[i].fillna(df[i].median())\n",
    "df.isnull().sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469011b3",
   "metadata": {},
   "source": [
    "## Treating outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d158df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,10))\n",
    "sns.boxplot(data=df)\n",
    "plt.title('The boxplot to study outliers')\n",
    "plt.xlabel('Variables that predict the customer churn')\n",
    "plt.ylabel('Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a83e30",
   "metadata": {},
   "source": [
    "after checking outliers now we remove those outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a52f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(col):\n",
    "    sorted(col)\n",
    "    Q1,Q3=np.percentile(col,[25,75])\n",
    "    IQR=Q3-Q1\n",
    "    lr= Q1-(1.5 * IQR)\n",
    "    ur= Q3+(1.5 * IQR)\n",
    "    return lr, ur\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype !='object':\n",
    "        lr,ur=remove_outlier(df[column])\n",
    "        df[column]=np.where(df[column]>ur,ur,df[column])\n",
    "        df[column]=np.where(df[column]<lr,lr,df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7eb13",
   "metadata": {},
   "source": [
    "Now plotting again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af367ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,10))\n",
    "sns.boxplot(data=df)\n",
    "plt.title('The boxplot to study outliers')\n",
    "plt.xlabel('Variables that predict the customer churn')\n",
    "plt.ylabel('Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c4698",
   "metadata": {},
   "source": [
    "##Adding a new variable \n",
    "cashback per order -> cashbackamout+ordercount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fd428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_cashbk_per_order']=df['CashbackAmount']/df['OrderCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d2ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Churn_perc = round((df['Churn'][df['Churn']==1].count()*100/df['Churn'][df['Churn']==0].count()),2)\n",
    "print(Churn_perc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133972a",
   "metadata": {},
   "source": [
    "## Data Analysis \n",
    "1) univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f29fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=[]\n",
    "num=[]\n",
    "for i in df.columns:\n",
    "  if df[i].dtype=='object':\n",
    "    cat.append(i)\n",
    "  else:\n",
    "    num.append(i)\n",
    "print('cat = ',cat)\n",
    "print('num = ',num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764957ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat:\n",
    "    print(i)\n",
    "    print()\n",
    "    print(df[i].value_counts())\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c4feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num].hist(figsize=(40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8, 2, figsize=(40, 40))\n",
    "for i, subplot in zip(num, ax.flatten()):\n",
    "    sns.histplot(df[i], ax=subplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d9aa3",
   "metadata": {},
   "source": [
    "##Analysing churn by each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c8b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for i in df.columns:\n",
    "    # Group by the column and get the sum of 'Churn', renaming it to 'Customers_churned'\n",
    "    churn_sum = df.groupby(i).Churn.sum().rename('Customers_churned')\n",
    "    \n",
    "    # Get value counts for the column\n",
    "    value_counts = df[i].value_counts().rename('Total_Customers')\n",
    "    \n",
    "    # Calculate percentage (ensure both are aligned first)\n",
    "    perc_of_total_cust = (churn_sum * 100 / value_counts).round(2).rename('perc_of_total_cust')\n",
    "    \n",
    "    # Combine them into a single DataFrame\n",
    "    temp_df = pd.concat([churn_sum, value_counts, perc_of_total_cust], axis=1)\n",
    "    \n",
    "    # Reset the index and rename the index column\n",
    "    temp_df.reset_index(level=0, inplace=True)\n",
    "    temp_df = temp_df.rename(columns={ 'index': i })\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    d[i] = temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(i)\n",
    "    print(d[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476c5c9",
   "metadata": {},
   "source": [
    "## Analysing churn by each variable --by visualising via graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_chart(variable):\n",
    "  # definig the plot for matplotlib\n",
    "  plt.figure(figsize=(20,12))\n",
    "  fig, ax = plt.subplots()\n",
    "  # defining the title\n",
    "  title1 = 'Customers Churn analysed by ' + variable\n",
    "  plt.title(title1)\n",
    "  # defining the lines for the y -axis\n",
    "  line1 = ax.plot(d[variable][variable],d[variable]['Customers_churned'], color='lightskyblue', label = 'Customers churned')\n",
    "  line2 = ax.plot(d[variable][variable],d[variable]['Total_Customers'], color='dodgerblue', label = 'Total Customers')\n",
    "  # labelling the x -axis and y-axis\n",
    "  plt.xlabel (variable)\n",
    "  plt.ylabel ('No. of customers')\n",
    "  # rotating the labels on the x-axis for better visualisation\n",
    "  for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "  # defining another axis on the right side of the graph\n",
    "  ax2=ax.twinx()\n",
    "  # defining the line for the right side y -axis\n",
    "  line3 = ax2.plot(d[variable][variable],d[variable]['perc_of_total_cust'], color='yellowgreen', label = 'Churn as Percent of total')\n",
    "  y = 0*d[variable]['perc_of_total_cust']+20.25\n",
    "  line4 = ax2.plot(d[variable][variable], y, color='orangered', label='Average customer Churn', linestyle='dashed')\n",
    "  # labelling the right side y-axis\n",
    "  plt.ylabel ('percentage of customers churned')\n",
    "  # adding the three lines to show the legend on the right corner in a coherent place, not doing this will lead to overlapping of legends of lines belonging to left and right y axis\n",
    "  lines = line1+line2+line3+line4\n",
    "  labs = [l.get_label() for l in lines]\n",
    "  ax.legend(lines, labs, bbox_to_anchor=(1.7, 1))\n",
    "  # adding sns palette for better visualisation\n",
    "  sns.despine(ax=ax, right=True, left=True)\n",
    "  sns.despine(ax=ax2, left=True, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb63c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Tenure', 'PreferredLoginDevice', 'CityTier',\n",
    "       'WarehouseToHome', 'PreferredPaymentMode', 'Gender', 'HourSpendOnApp',\n",
    "       'NumberOfDeviceRegistered', 'PreferedOrderCat', 'SatisfactionScore',\n",
    "       'MaritalStatus', 'NumberOfAddress', 'Complain',\n",
    "       'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount',\n",
    "       'DaySinceLastOrder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_chart('Tenure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050eab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_chart('CityTier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_chart('WarehouseToHome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ae030",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_chart('PreferredPaymentMode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5159ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_chart('Gender')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ea180",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_chart('HourSpendOnApp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_chart('NumberOfDeviceRegistered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c0cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_chart('PreferedOrderCat')\n",
    "analysis_chart('SatisfactionScore')\n",
    "analysis_chart('MaritalStatus')\n",
    "analysis_chart('NumberOfAddress')\n",
    "analysis_chart('Complain')\n",
    "analysis_chart('OrderAmountHikeFromlastYear')\n",
    "analysis_chart('CouponUsed')\n",
    "analysis_chart('OrderCount')\n",
    "analysis_chart('DaySinceLastOrder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the loop for automating the figure generation\n",
    "# Writing the loop for one dataframe at a time since we need to have the figures in separate cells so that it becomes easy to analyse and write the conclusion there only.\n",
    "for i in ['avg_cashbk_per_order']:\n",
    "    # definig the plot for matplotlib\n",
    "    plt.figure(figsize=(20,12))\n",
    "    fig, ax = plt.subplots()\n",
    "    # defining the title\n",
    "    title1 = 'Customers Churn analysed by ' + i\n",
    "    plt.title(title1)\n",
    "    # defining the lines for the y -axis\n",
    "    line1 = ax.scatter(d[i][i],d[i]['Customers_churned'], color='lightskyblue', label = 'Customers churned')\n",
    "    line2 = ax.scatter(d[i][i],d[i]['Total_Customers'], color='dodgerblue', label = 'Total Customers')\n",
    "    # labelling the x -axis and y-axis\n",
    "    plt.xlabel (i)\n",
    "    plt.ylabel ('No. of customers')\n",
    "    # rotating the labels on the x-axis for better visualisation\n",
    "    for tick in ax.get_xticklabels():\n",
    "      tick.set_rotation(45)\n",
    "    # defining another axis on the right side of the graph\n",
    "    ax2=ax.twinx()\n",
    "    # defining the line for the right side y -axis\n",
    "    line3 = ax2.scatter(d[i][i],d[i]['perc_of_total_cust'], color='yellowgreen', label = 'Churn as Percent of total')\n",
    "    # labelling the right side y-axis\n",
    "    plt.ylabel ('percentage of customers churned')\n",
    "    # adding sns palette for better visualisation\n",
    "    sns.despine(ax=ax, right=True, left=True)\n",
    "    sns.despine(ax=ax2, left=True, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082b73e",
   "metadata": {},
   "source": [
    "# Bivariate analysis (some error currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "# sns.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1153be",
   "metadata": {},
   "source": [
    "# One hot encoding and Scaling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a746cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c9186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded=df.copy()\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819df175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_encoded,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c921b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_encoded[num]\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48efcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df_encoded = df_encoded.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df_encoded[num] = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b27b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c22575",
   "metadata": {},
   "source": [
    "# Now our data is preprocessed and ready to be used for training our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a034c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying dataset in new variable\n",
    "scaled_df_encoded_h = scaled_df_encoded.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7251aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87058c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_method=linkage(scaled_df_encoded_h,method = 'average')\n",
    "print(link_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6472ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labellist = np.array(scaled_df_encoded_h.Churn_1)\n",
    "labellist\n",
    "print(len(labellist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "dend = dendrogram(link_method,labels=labellist)\n",
    "dend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dend = dendrogram(link_method,labels=labellist,truncate_mode='lastp',p=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3564fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_max = fcluster(link_method,4,criterion = 'maxclust')\n",
    "clusters_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df_encoded_h['clusters_max'] = clusters_max\n",
    "scaled_df_encoded_h.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = df.copy()\n",
    "df_h['clusters_max'] = clusters_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ae539",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata_max = scaled_df_encoded_h.iloc[:,:].groupby('clusters_max').median()\n",
    "aggdata_max['freq'] = scaled_df_encoded_h.clusters_max.value_counts().sort_index()\n",
    "aggdata_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a335d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata_max_2 = df_h.iloc[:,:].groupby('clusters_max').mean()\n",
    "aggdata_max_2['freq'] = df_h.clusters_max.value_counts().sort_index()\n",
    "aggdata_max_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760a5a9",
   "metadata": {},
   "source": [
    "## IMPLEMENTING K MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df_encoded_k= scaled_df_encoded.copy()\n",
    "from sklearn.cluster import KMeans \n",
    "k_means = KMeans(n_clusters = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ebc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.fit(scaled_df_encoded_k)\n",
    "k_means.labels_\n",
    "k_means.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 3)\n",
    "k_means.fit(scaled_df_encoded_k)\n",
    "k_means.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 4)\n",
    "k_means.fit(scaled_df_encoded_k)\n",
    "k_means.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 5)\n",
    "k_means.fit(scaled_df_encoded_k)\n",
    "k_means.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d1c6e",
   "metadata": {},
   "source": [
    "##INSTEAD OF DOING THIS, WE USE FOR LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f099c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wss =[] \n",
    "for i in range(1,20):\n",
    "    k_means = KMeans(n_clusters=i)\n",
    "    k_means.fit(scaled_df_encoded_k)\n",
    "    wss.append(k_means.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,20), wss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "# Silhoutte score for 2 cluster\n",
    "Sil_Score = []\n",
    "for i in range(2,20):\n",
    "  k_means = KMeans(n_clusters=i)\n",
    "  k_means.fit(scaled_df_encoded_k)\n",
    "  labels = k_means.labels_\n",
    "  ss = silhouette_score(scaled_df_encoded_k,labels)\n",
    "  Sil_Score.append(ss)\n",
    "\n",
    "\n",
    "Sil_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking ideal number of clusters as 4\n",
    "k_means = KMeans(n_clusters = 4)\n",
    "k_means.fit(scaled_df_encoded_k)\n",
    "labels = k_means.labels_\n",
    "\n",
    "\n",
    "scaled_df_encoded_k[\"Clus_kmeans\"] = labels\n",
    "scaled_df_encoded_k.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata_k = scaled_df_encoded_k.iloc[:,:].groupby('Clus_kmeans').mean()\n",
    "aggdata_k['freq'] = scaled_df_encoded_k.Clus_kmeans.value_counts().sort_index()\n",
    "aggdata_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing clusters on original dataset\n",
    "df_k = df.copy()\n",
    "df_k['Clus_kmeans'] = scaled_df_encoded_k[\"Clus_kmeans\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata_k2 = df_k.select_dtypes(include='number').groupby(df_k['Clus_kmeans']).mean()\n",
    "aggdata_k2['freq'] = df_k.Clus_kmeans.value_counts().sort_index()\n",
    "aggdata_k2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984994d1",
   "metadata": {},
   "source": [
    "## Building classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b350a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df_encoded_h['clusters_max'] = scaled_df_encoded_h['clusters_max'].astype('object')\n",
    "scaled_df_encoded_h1 = pd.get_dummies(scaled_df_encoded_h, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e62f4b",
   "metadata": {},
   "source": [
    "# SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfd55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=scaled_df_encoded_h1.drop(['Churn_1'],axis=1)\n",
    "y=scaled_df_encoded_h1['Churn_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before OverSampling, the shape of X: {}'.format(X.shape)) \n",
    "print('Before OverSampling, the shape of y: {} \\n'.format(y.shape)) \n",
    "  \n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y == 1))) \n",
    "print(\"Before OverSampling, counts of label '0': {}\".format(sum(y == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75462f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state=33)\n",
    "X_res, y_res = sm.fit_resample(X, y.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of X: {}'.format(X_res.shape)) \n",
    "print('After OverSampling, the shape of y: {} \\n'.format(y_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res=pd.DataFrame(X_res)\n",
    "y_res=pd.DataFrame(y_res)\n",
    "y_res.columns = ['Churn_1']\n",
    "scaled_df_encoded_h1_smote = pd.concat([X_res,y_res], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee3610f",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47004a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = scaled_df_encoded_h1_smote.drop(['Churn_1'],axis=1)\n",
    "y = scaled_df_encoded_h1_smote['Churn_1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd9f8d",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80505e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0168b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_predict = model_lr.predict(X_train)\n",
    "ytest_predict = model_lr.predict(X_test)\n",
    "ytest_predict_prob=model_lr.predict_proba(X_test)\n",
    "pd.DataFrame(ytest_predict_prob).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy - Training Data\n",
    "model_lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,roc_curve,classification_report,confusion_matrix\n",
    "# predict probabilities\n",
    "probs = model_lr.predict_proba(X_train)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_train, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f861e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy - Test Data\n",
    "model_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = model_lr.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "test_auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(test_fpr, test_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07990d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix training Data\n",
    "cm_lr = confusion_matrix(y_train, ytrain_predict)\n",
    "cm_lr\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.heatmap(cm_lr,annot = True,fmt = 'd', cmap ='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, ytrain_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1151435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix test Data\n",
    "cm_test_lr=confusion_matrix(y_test, ytest_predict)\n",
    "cm_test_lr\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.heatmap(cm_test_lr,annot = True,fmt = 'd', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data Accuracy\n",
    "test_acc=model_lr.score(X_test,y_test)\n",
    "test_acc\n",
    "print(classification_report(y_test, ytest_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8f283",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "LDA_model= LinearDiscriminantAnalysis()\n",
    "LDA_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e9cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Matrix on train data set\n",
    "y_train_predict = LDA_model.predict(X_train)\n",
    "model_score = LDA_model.score(X_train, y_train)\n",
    "print(model_score)\n",
    "#confusion matrix training Data\n",
    "cm_train_lda = confusion_matrix(y_train, y_train_predict)\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.heatmap(cm_train_lda, annot = True,fmt = 'd', cmap='rainbow')\n",
    "print(metrics.classification_report(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74018678",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Matrix on test data set\n",
    "y_test_predict = LDA_model.predict(X_test)\n",
    "model_score = LDA_model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "#confusion matrix test Data\n",
    "cm_test_lda = confusion_matrix(y_test, y_test_predict)\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.heatmap(cm_test_lda, annot = True,fmt = 'd', cmap='rainbow')\n",
    "print(metrics.classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0943d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = LDA_model.predict_proba(X_train)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_train, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45120879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = LDA_model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "test_auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(test_fpr, test_tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89147c00",
   "metadata": {},
   "source": [
    "## Desision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b380f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "DT_model= tree.DecisionTreeClassifier()\n",
    "DT_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Matrix on train data set\n",
    "y_train_predict = DT_model.predict(X_train)\n",
    "model_score = DT_model.score(X_train, y_train)\n",
    "print(model_score)\n",
    "print(metrics.classification_report(y_train, y_train_predict))\n",
    "#confusion matrix training Data\n",
    "cm_train_dt = confusion_matrix(y_train, y_train_predict)\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.heatmap(cm_train_dt, annot = True,fmt = 'd', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Matrix on test data set\n",
    "y_test_predict = DT_model.predict(X_test)\n",
    "model_score = DT_model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "print(metrics.classification_report(y_test, y_test_predict))\n",
    "#confusion matrix test Data\n",
    "cm_test_dt = confusion_matrix(y_test, y_test_predict)\n",
    "sns.set(font_scale = 1.2)\n",
    "print('Confusion Matrix')\n",
    "sns.heatmap(cm_test_dt, annot = True,fmt = 'd', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = DT_model.predict_proba(X_train)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_train, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = DT_model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "test_auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(test_fpr, test_tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893fd84",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_model=RandomForestClassifier(n_estimators=100,random_state=1)\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276834c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Matrix on train data set\n",
    "y_train_predict = RF_model.predict(X_train)\n",
    "model_score =RF_model.score(X_train, y_train)\n",
    "print(model_score)\n",
    "print(metrics.classification_report(y_train, y_train_predict))\n",
    "#confusion matrix training Data\n",
    "cm_train_rf = confusion_matrix(y_train, y_train_predict)\n",
    "print('Confusion Matrix')\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.heatmap(cm_train_rf, annot = True,fmt = 'd', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Matrix on test data set\n",
    "y_test_predict = RF_model.predict(X_test)\n",
    "model_score = RF_model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "print(metrics.classification_report(y_test, y_test_predict))\n",
    "#confusion matrix test Data\n",
    "cm_test_rf = confusion_matrix(y_test, y_test_predict)\n",
    "sns.set(font_scale = 1.2)\n",
    "print('Confusion Matrix')\n",
    "sns.heatmap(cm_test_rf, annot = True,fmt = 'd', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = RF_model.predict_proba(X_train)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_train, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b734e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = RF_model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "test_auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(test_fpr, test_tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f8619",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN_model=KNeighborsClassifier()\n",
    "KNN_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338eca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Matrix on train data set\n",
    "y_train_predict = KNN_model.predict(X_train)\n",
    "model_score = KNN_model.score(X_train, y_train)\n",
    "print(model_score)\n",
    "print(metrics.classification_report(y_train, y_train_predict))\n",
    "#confusion matrix training Data\n",
    "cm_train_knn = confusion_matrix(y_train, y_train_predict)\n",
    "print('Confusion Matrix')\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.heatmap(cm_train_knn, annot = True,fmt = 'd', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d1d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Matrix on test data set\n",
    "y_test_predict = KNN_model.predict(X_test)\n",
    "model_score = KNN_model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "print(metrics.classification_report(y_test, y_test_predict))\n",
    "#confusion matrix test Data\n",
    "cm_test_knn = confusion_matrix(y_test, y_test_predict)\n",
    "sns.set(font_scale = 1.2)\n",
    "print('Confusion Matrix')\n",
    "sns.heatmap(cm_test_knn, annot = True,fmt = 'd', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = KNN_model.predict_proba(X_train)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_train, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = KNN_model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "test_auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(test_fpr, test_tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9b8f04",
   "metadata": {},
   "source": [
    "## XG-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "XGB_model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "XGB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Matrix on train data set\n",
    "y_train_predict = XGB_model.predict(X_train)\n",
    "model_score = XGB_model.score(X_train, y_train)\n",
    "print(model_score)\n",
    "print(metrics.classification_report(y_train, y_train_predict))\n",
    "#confusion matrix training Data\n",
    "cm_train_knn = confusion_matrix(y_train, y_train_predict)\n",
    "print('Confusion Matrix')\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.heatmap(cm_train_knn, annot = True,fmt = 'd', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e32fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Matrix on test data set\n",
    "y_test_predict = XGB_model.predict(X_test)\n",
    "model_score = XGB_model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "print(metrics.classification_report(y_test, y_test_predict))\n",
    "#confusion matrix test Data\n",
    "cm_test_knn = confusion_matrix(y_test, y_test_predict)\n",
    "sns.set(font_scale = 1.2)\n",
    "print('Confusion Matrix')\n",
    "sns.heatmap(cm_test_knn, annot = True,fmt = 'd', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b52f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = XGB_model.predict_proba(X_train)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_train, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(train_fpr, train_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527048a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = XGB_model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "test_auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(test_fpr, test_tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
